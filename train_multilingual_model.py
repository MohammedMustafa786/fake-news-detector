#!/usr/bin/env python3
"""
Enhanced Multilingual Fake News Detection Training
Trains models on English, Spanish, French, and Hindi datasets
"""
import pandas as pd
import numpy as np
from pathlib import Path
from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from sklearn.naive_bayes import MultinomialNB
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
import pickle
import time
from multilingual_preprocessing import MultilingualPreprocessor
import warnings
warnings.filterwarnings('ignore')

class MultilingualFakeNewsTrainer:
    """
    Enhanced multilingual trainer for fake news detection.
    """
    
    def __init__(self):
        self.models_dir = Path("models_multilingual")
        self.models_dir.mkdir(exist_ok=True)
        
        self.preprocessor = None
        self.best_model = None
        self.best_score = 0
        
        # Model configurations
        self.models = {
            'RandomForest': RandomForestClassifier(
                n_estimators=200,
                max_depth=20,
                min_samples_split=5,
                min_samples_leaf=2,
                random_state=42,
                n_jobs=-1
            ),
            'LogisticRegression': LogisticRegression(
                random_state=42,
                max_iter=1000,
                solver='liblinear',
                C=1.0
            ),
            'GradientBoosting': GradientBoostingClassifier(
                n_estimators=100,
                learning_rate=0.1,
                max_depth=6,
                random_state=42
            ),
            'MultinomialNB': MultinomialNB(alpha=0.1),
            'SVM': SVC(
                kernel='linear',
                C=1.0,
                random_state=42,
                probability=True
            )
        }
    
    def load_dataset(self, dataset_path="data/enhanced_multilingual_fake_news_dataset.csv"):
        """Load the multilingual dataset."""
        print("üìÅ Loading multilingual dataset...")
        
        if not Path(dataset_path).exists():
            raise FileNotFoundError(f"Dataset not found: {dataset_path}")
        
        df = pd.read_csv(dataset_path)
        
        print(f"   ‚úÖ Dataset loaded!")
        print(f"   üìä Total articles: {len(df):,}")
        print(f"   üåç Languages: {', '.join(df['language'].unique())}")
        
        # Show language distribution
        print(f"\nüåê Dataset Language Distribution:")
        for lang in df['language'].unique():
            lang_count = len(df[df['language'] == lang])
            fake_count = len(df[(df['language'] == lang) & (df['label'] == 1)])
            real_count = len(df[(df['language'] == lang) & (df['label'] == 0)])
            percentage = lang_count / len(df) * 100
            print(f"   {lang.title()}: {lang_count:,} articles ({percentage:.1f}%) - Real: {real_count:,}, Fake: {fake_count:,}")
        
        # Check label distribution
        label_counts = df['label'].value_counts()
        print(f"\nüìä Label Distribution:")
        print(f"   Real (0): {label_counts.get(0, 0):,} articles ({label_counts.get(0, 0)/len(df)*100:.1f}%)")
        print(f"   Fake (1): {label_counts.get(1, 0):,} articles ({label_counts.get(1, 0)/len(df)*100:.1f}%)")
        
        return df
    
    def preprocess_data(self, df, sample_size=None):
        """Preprocess the multilingual data."""
        print(f"\nüîß Preprocessing multilingual data...")
        
        if sample_size and len(df) > sample_size:
            print(f"   üìè Sampling {sample_size:,} articles for training...")
            df = df.sample(n=sample_size, random_state=42).reset_index(drop=True)
        
        # Initialize preprocessor
        self.preprocessor = MultilingualPreprocessor(max_features=20000)
        
        # Preprocess and vectorize
        X, y, processed_df = self.preprocessor.process_and_vectorize(df)
        
        return X, y, processed_df
    
    def train_and_evaluate_models(self, X, y, processed_df):
        """Train and evaluate all models with multilingual cross-validation."""
        print(f"\nüöÄ Training multilingual fake news detection models...")
        print(f"   üìä Training set: {X.shape[0]:,} articles")
        print(f"   üî¢ Features: {X.shape[1]:,}")
        
        # Split data while maintaining language distribution
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=0.2, random_state=42, stratify=y
        )
        
        # Get corresponding language info for analysis
        train_indices = X_train.indices if hasattr(X_train, 'indices') else range(len(y_train))
        test_indices = X_test.indices if hasattr(X_test, 'indices') else range(len(y_train), len(y))
        
        results = {}
        
        for name, model in self.models.items():
            print(f"\nüîß Training {name}...")
            start_time = time.time()
            
            # Train model
            model.fit(X_train, y_train)
            
            # Cross-validation
            cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)
            cv_scores = cross_val_score(model, X_train, y_train, cv=cv, scoring='accuracy')
            
            # Test predictions
            y_pred = model.predict(X_test)
            test_accuracy = accuracy_score(y_test, y_pred)
            
            training_time = time.time() - start_time
            
            # Store results
            results[name] = {
                'model': model,
                'cv_scores': cv_scores,
                'cv_mean': cv_scores.mean(),
                'cv_std': cv_scores.std(),
                'test_accuracy': test_accuracy,
                'training_time': training_time,
                'y_pred': y_pred
            }
            
            print(f"   ‚úÖ {name} completed!")
            print(f"      üéØ CV Accuracy: {cv_scores.mean():.4f} (¬±{cv_scores.std():.4f})")
            print(f"      üìà Test Accuracy: {test_accuracy:.4f}")
            print(f"      ‚è±Ô∏è  Training Time: {training_time:.2f}s")
            
            # Update best model
            if cv_scores.mean() > self.best_score:
                self.best_score = cv_scores.mean()
                self.best_model = model
                print(f"      üåü New best model!")
        
        # Detailed evaluation of best model
        best_name = max(results.keys(), key=lambda k: results[k]['cv_mean'])
        print(f"\nüèÜ Best Model: {best_name}")
        print(f"   üéØ CV Accuracy: {results[best_name]['cv_mean']:.4f} (¬±{results[best_name]['cv_std']:.4f})")
        print(f"   üìà Test Accuracy: {results[best_name]['test_accuracy']:.4f}")
        
        # Classification report for best model
        best_pred = results[best_name]['y_pred']
        print(f"\nüìä Detailed Classification Report ({best_name}):")
        print(classification_report(y_test, best_pred, target_names=['Real', 'Fake']))
        
        return results, X_test, y_test
    
    def analyze_multilingual_performance(self, X_test, y_test, processed_df, results):
        """Analyze performance across different languages."""
        print(f"\nüåê Multilingual Performance Analysis...")
        
        best_name = max(results.keys(), key=lambda k: results[k]['cv_mean'])
        best_model = results[best_name]['model']
        
        # Create test samples for each language
        language_samples = {
            'english': "This is breaking news about a major political scandal that will shock you.",
            'spanish': "URGENTE: Nueva evidencia revela la verdad oculta sobre esc√°ndalos pol√≠ticos.", 
            'french': "EXCLUSIF: De nouvelles preuves r√©v√®lent la v√©rit√© cach√©e sur les scandales politiques.",
            'hindi': "‡§§‡§§‡•ç‡§ï‡§æ‡§≤: ‡§∞‡§æ‡§ú‡§®‡•Ä‡§§‡§ø‡§ï ‡§ò‡•ã‡§ü‡§æ‡§≤‡•ã‡§Ç ‡§ï‡•á ‡§¨‡§æ‡§∞‡•á ‡§Æ‡•á‡§Ç ‡§õ‡•Å‡§™‡•á ‡§π‡•Å‡§è ‡§∏‡§ö ‡§ï‡§æ ‡§®‡§Ø‡§æ ‡§∏‡§¨‡•Ç‡§§ ‡§Æ‡§ø‡§≤‡§æ‡•§"
        }
        
        print(f"\nüß™ Testing {best_name} on multilingual samples:")
        
        for language, sample_text in language_samples.items():
            # Create a sample dataframe
            sample_df = pd.DataFrame({
                'text': [sample_text],
                'label': [1],  # Assume fake for testing
                'language': [language]
            })
            
            # Preprocess
            X_sample = self.preprocessor.vectorize_texts(
                self.preprocessor.preprocess_dataset(sample_df)['processed_text'], 
                fit=False
            )
            
            # Predict
            prediction = best_model.predict(X_sample)[0]
            confidence = best_model.predict_proba(X_sample)[0].max()
            
            result = "Fake" if prediction == 1 else "Real"
            print(f"   {language.title()}: {result} (Confidence: {confidence:.3f})")
    
    def save_models(self, results):
        """Save trained models and preprocessor."""
        print(f"\nüíæ Saving multilingual models...")
        
        # Save preprocessor
        preprocessor_file = self.models_dir / 'multilingual_preprocessor.pkl'
        with open(preprocessor_file, 'wb') as f:
            pickle.dump(self.preprocessor, f)
        print(f"   ‚úÖ Preprocessor saved: {preprocessor_file}")
        
        # Save all models
        for name, result in results.items():
            model_file = self.models_dir / f'multilingual_{name.lower()}_model.pkl'
            with open(model_file, 'wb') as f:
                pickle.dump(result['model'], f)
            print(f"   ‚úÖ {name} model saved: {model_file}")
        
        # Save best model separately
        best_name = max(results.keys(), key=lambda k: results[k]['cv_mean'])
        best_model_file = self.models_dir / 'multilingual_best_model.pkl'
        with open(best_model_file, 'wb') as f:
            pickle.dump(results[best_name]['model'], f)
        print(f"   üåü Best model ({best_name}) saved: {best_model_file}")
        
        # Save training results
        results_df = pd.DataFrame({
            'Model': list(results.keys()),
            'CV_Mean': [results[name]['cv_mean'] for name in results.keys()],
            'CV_Std': [results[name]['cv_std'] for name in results.keys()],
            'Test_Accuracy': [results[name]['test_accuracy'] for name in results.keys()],
            'Training_Time': [results[name]['training_time'] for name in results.keys()]
        })
        
        results_file = self.models_dir / 'multilingual_training_results.csv'
        results_df.to_csv(results_file, index=False)
        print(f"   üìä Training results saved: {results_file}")
        
        return best_name
    
    def train_full_pipeline(self, sample_size=15000):
        """Complete multilingual training pipeline."""
        print("üåê" * 20)
        print("  MULTILINGUAL FAKE NEWS DETECTION TRAINING")
        print("üåê" * 20)
        
        try:
            # Load dataset
            df = self.load_dataset()
            
            # Preprocess data
            X, y, processed_df = self.preprocess_data(df, sample_size=sample_size)
            
            # Train and evaluate models
            results, X_test, y_test = self.train_and_evaluate_models(X, y, processed_df)
            
            # Analyze multilingual performance
            self.analyze_multilingual_performance(X_test, y_test, processed_df, results)
            
            # Save models
            best_name = self.save_models(results)
            
            print(f"\nüéâ Multilingual Training Complete!")
            print(f"   üèÜ Best Model: {best_name}")
            print(f"   üéØ Best CV Score: {self.best_score:.4f}")
            print(f"   üåç Languages Supported: English, Spanish, French, Hindi")
            print(f"   üìÅ Models saved in: {self.models_dir}/")
            print(f"\n‚úÖ Your Spanish confidence issue should now be resolved!")
            print(f"‚úÖ Model can now handle French and Hindi inputs with confidence!")
            
        except Exception as e:
            print(f"\n‚ùå Training failed: {str(e)}")
            import traceback
            traceback.print_exc()

def main():
    """Main execution function."""
    trainer = MultilingualFakeNewsTrainer()
    
    # Train with a reasonable sample size
    trainer.train_full_pipeline(sample_size=15000)

if __name__ == "__main__":
    main()
